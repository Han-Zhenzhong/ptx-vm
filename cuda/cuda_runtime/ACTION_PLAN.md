# å®ç° libptxrt åŠŸèƒ½çš„æœ€å°è¡ŒåŠ¨æ¸…å•

## ğŸ¯ ç›®æ ‡
è®© `simple_add.cu` èƒ½åœ¨ PTX VM ä¸Šè¿è¡Œ

---

## âœ… æ ¸å¿ƒä»»åŠ¡ï¼ˆæŒ‰é¡ºåºæ‰§è¡Œï¼‰

### ä»»åŠ¡ 1: é›†æˆ HostAPI (30åˆ†é’Ÿ)

**ä¿®æ”¹æ–‡ä»¶**: `cuda/cuda_runtime/CMakeLists.txt`

```cmake
# åœ¨ CMakeLists.txt ä¸­æ·»åŠ 

# æ‰¾åˆ° PTX VM çš„å¤´æ–‡ä»¶å’Œåº“
include_directories(
    ${CMAKE_CURRENT_SOURCE_DIR}
    ${CMAKE_SOURCE_DIR}/include  # PTX VM å¤´æ–‡ä»¶
    ${CMAKE_SOURCE_DIR}/src      # å¦‚æœéœ€è¦
)

# é“¾æ¥ PTX VM åº“
# å‡è®¾å·²ç»æ„å»ºäº† PTX VMï¼Œåº“åœ¨ build/ ç›®å½•
link_directories(
    ${CMAKE_SOURCE_DIR}/build
)

# ä¿®æ”¹é™æ€åº“é“¾æ¥
target_link_libraries(ptxrt_static PUBLIC
    # æ·»åŠ  PTX VM çš„åº“ï¼ˆåå­—å¾…ç¡®è®¤ï¼‰
    # ptx_vm æˆ–å…¶ä»–
)

# ä¿®æ”¹åŠ¨æ€åº“é“¾æ¥
target_link_libraries(ptxrt_shared PUBLIC
    # æ·»åŠ  PTX VM çš„åº“
)
```

**éªŒè¯**: ç¼–è¯‘é€šè¿‡ï¼Œå¯ä»¥ `#include "host_api.hpp"`

---

### ä»»åŠ¡ 2: å®ç°å†…å­˜ç®¡ç† (1å°æ—¶)

**ä¿®æ”¹æ–‡ä»¶**: `cuda/cuda_runtime/cuda_runtime.cpp`

**æ·»åŠ å¤´æ–‡ä»¶**:
```cpp
#include "host_api.hpp"
#include "cuda_runtime_internal.h"
```

**ä¿®æ”¹ RuntimeState**ï¼ˆåœ¨ `cuda_runtime_internal.h`ï¼‰:
```cpp
class RuntimeState {
public:
    HostAPI host_api;  // HostAPI å®ä¾‹
    // ... å…¶ä»–æˆå‘˜
    
    RuntimeState() {
        host_api.initialize();
        host_api.cuInit(0);
    }
};
```

**å®ç° 3 ä¸ªå‡½æ•°**:

```cpp
cudaError_t cudaMalloc(void** devPtr, size_t size) {
    auto& state = RuntimeState::getInstance();
    CUdeviceptr ptr;
    
    CUresult result = state.host_api.cuMemAlloc(&ptr, size);
    if (result != CUDA_SUCCESS) {
        return cudaErrorMemoryAllocation;
    }
    
    *devPtr = reinterpret_cast<void*>(ptr);
    return cudaSuccess;
}

cudaError_t cudaFree(void* devPtr) {
    auto& state = RuntimeState::getInstance();
    CUdeviceptr ptr = reinterpret_cast<CUdeviceptr>(devPtr);
    
    CUresult result = state.host_api.cuMemFree(ptr);
    return (result == CUDA_SUCCESS) ? cudaSuccess : cudaErrorUnknown;
}

cudaError_t cudaMemcpy(void* dst, const void* src, size_t count, 
                       enum cudaMemcpyKind kind) {
    auto& state = RuntimeState::getInstance();
    CUresult result;
    
    if (kind == cudaMemcpyHostToDevice) {
        result = state.host_api.cuMemcpyHtoD(
            reinterpret_cast<CUdeviceptr>(dst), src, count);
    } else if (kind == cudaMemcpyDeviceToHost) {
        result = state.host_api.cuMemcpyDtoH(
            dst, reinterpret_cast<CUdeviceptr>(src), count);
    } else {
        return cudaErrorInvalidMemcpyDirection;
    }
    
    return (result == CUDA_SUCCESS) ? cudaSuccess : cudaErrorUnknown;
}
```

**éªŒè¯**: ç¼–è¯‘é€šè¿‡

---

### ä»»åŠ¡ 3: å®ç°å†…æ ¸æ³¨å†Œ (1å°æ—¶)

**ä¿®æ”¹ RuntimeState** æ·»åŠ æ˜ å°„è¡¨:
```cpp
class RuntimeState {
public:
    std::map<const void*, KernelInfo> kernel_map;  // hostæŒ‡é’ˆ â†’ å†…æ ¸ä¿¡æ¯
    std::string ptx_file_path;  // PTX æ–‡ä»¶è·¯å¾„
    bool program_loaded = false;
};
```

**å®ç° 2 ä¸ªå‡½æ•°**:

```cpp
void** __cudaRegisterFatBinary(void* fatCubin) {
    // ç®€åŒ–ç‰ˆæœ¬ï¼šä¸è§£æ fat binary
    static void* handle = malloc(8);
    
    printf("[libptxrt] Fat binary registered\n");
    printf("[libptxrt] NOTE: Please set PTX file via PTXRT_PTX_PATH env var\n");
    
    return &handle;
}

void __cudaRegisterFunction(void** fatCubinHandle,
                           const char* hostFun,
                           char* deviceFun,
                           const char* deviceName,
                           int thread_limit,
                           uint3* tid, uint3* bid,
                           dim3* bDim, dim3* gDim,
                           int* wSize) {
    auto& state = RuntimeState::getInstance();
    
    KernelInfo info;
    info.kernel_name = deviceName;
    info.host_func = (const void*)hostFun;
    
    state.kernel_map[(const void*)hostFun] = info;
    
    printf("[libptxrt] Kernel registered: %s at %p\n", 
           deviceName, hostFun);
}
```

**éªŒè¯**: ç¼–è¯‘é€šè¿‡

---

### ä»»åŠ¡ 4: å®ç°å†…æ ¸å¯åŠ¨ï¼ˆå« <<<>>> è¯­æ³•æ”¯æŒï¼‰(2-3å°æ—¶)

**è¿™æ˜¯æœ€å…³é”®çš„éƒ¨åˆ†ï¼**

**å®ç°**:

```cpp
cudaError_t cudaLaunchKernel(const void* func, dim3 gridDim, dim3 blockDim,
                             void** args, size_t sharedMem, cudaStream_t stream) {
    auto& state = RuntimeState::getInstance();
    
    // 1. æŸ¥æ‰¾å†…æ ¸
    auto it = state.kernel_map.find(func);
    if (it == state.kernel_map.end()) {
        fprintf(stderr, "[libptxrt] ERROR: Kernel not found\n");
        return cudaErrorInvalidValue;
    }
    
    const KernelInfo& kernel = it->second;
    printf("[libptxrt] Launching kernel: %s\n", kernel.kernel_name.c_str());
    printf("[libptxrt] Grid: (%u,%u,%u) Block: (%u,%u,%u)\n",
           gridDim.x, gridDim.y, gridDim.z,
           blockDim.x, blockDim.y, blockDim.z);
    
    // 2. åŠ è½½ PTX ç¨‹åºï¼ˆé¦–æ¬¡ï¼‰
    if (!state.program_loaded) {
        // ä»ç¯å¢ƒå˜é‡è·å– PTX è·¯å¾„
        const char* ptx_path = getenv("PTXRT_PTX_PATH");
        if (!ptx_path) {
            // é»˜è®¤å°è¯• kernel_name.ptx
            state.ptx_file_path = kernel.kernel_name + ".ptx";
        } else {
            state.ptx_file_path = ptx_path;
        }
        
        printf("[libptxrt] Loading PTX: %s\n", state.ptx_file_path.c_str());
        
        if (!state.host_api.loadProgram(state.ptx_file_path)) {
            fprintf(stderr, "[libptxrt] ERROR: Failed to load PTX\n");
            return cudaErrorInvalidSource;
        }
        
        state.program_loaded = true;
    }
    
    // 3. å¯åŠ¨å†…æ ¸
    // æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è·å– CUfunctionï¼Œå¯èƒ½éœ€è¦ä¿®æ”¹ HostAPI
    // æš‚æ—¶ä½¿ç”¨ 0 ä½œä¸ºå ä½ç¬¦
    CUfunction f = 0;  // TODO: éœ€è¦ä» kernel_name æŸ¥æ‰¾
    
    CUresult result = state.host_api.cuLaunchKernel(
        f,
        gridDim.x, gridDim.y, gridDim.z,
        blockDim.x, blockDim.y, blockDim.z,
        sharedMem,
        nullptr,  // stream
        args,
        nullptr   // extra
    );
    
    if (result != CUDA_SUCCESS) {
        fprintf(stderr, "[libptxrt] ERROR: Kernel launch failed\n");
        return cudaErrorLaunchFailure;
    }
    
    printf("[libptxrt] Kernel launched successfully\n");
    return cudaSuccess;
}
```

**å¯èƒ½éœ€è¦ä¿®æ”¹ HostAPI**:
åœ¨ `include/host_api.hpp` ä¸­æ·»åŠ ï¼š
```cpp
// æ·»åŠ æ–¹æ³•è·å–å‡½æ•° handle
CUresult cuModuleGetFunction(CUfunction* hfunc, const char* name);
```

**å®ç° <<<>>> è¯­æ³•æ”¯æŒ**ï¼ˆClang ä¼šè‡ªåŠ¨è°ƒç”¨è¿™äº›å‡½æ•°ï¼‰:

```cpp
// å…¨å±€å˜é‡ä¿å­˜å½“å‰é…ç½®
static thread_local LaunchConfig* g_current_config = nullptr;

cudaError_t cudaConfigureCall(dim3 gridDim, dim3 blockDim, 
                               size_t sharedMem, cudaStream_t stream) {
    // åˆ›å»ºæˆ–é‡ç½®é…ç½®
    if (!g_current_config) {
        g_current_config = new LaunchConfig();
    } else {
        g_current_config->args.clear();
        g_current_config->arg_sizes.clear();
    }
    
    g_current_config->grid_dim = gridDim;
    g_current_config->block_dim = blockDim;
    g_current_config->shared_mem = sharedMem;
    g_current_config->stream = stream;
    
    return cudaSuccess;
}

cudaError_t cudaSetupArgument(const void* arg, size_t size, size_t offset) {
    if (!g_current_config) {
        return cudaErrorInvalidValue;
    }
    
    // å¤åˆ¶å‚æ•°æ•°æ®
    void* arg_copy = malloc(size);
    memcpy(arg_copy, arg, size);
    
    g_current_config->args.push_back(arg_copy);
    g_current_config->arg_sizes.push_back(size);
    
    return cudaSuccess;
}

cudaError_t cudaLaunch(const void* func) {
    if (!g_current_config) {
        return cudaErrorInvalidValue;
    }
    
    // å‡†å¤‡å‚æ•°æ•°ç»„
    void** args = g_current_config->args.data();
    
    // è°ƒç”¨ cudaLaunchKernel
    cudaError_t result = cudaLaunchKernel(
        func,
        g_current_config->grid_dim,
        g_current_config->block_dim,
        args,
        g_current_config->shared_mem,
        g_current_config->stream
    );
    
    // æ¸…ç†å‚æ•°å‰¯æœ¬
    for (void* arg : g_current_config->args) {
        free(arg);
    }
    g_current_config->args.clear();
    g_current_config->arg_sizes.clear();
    
    return result;
}
```

**éªŒè¯**: ç¼–è¯‘é€šè¿‡

---

### ä»»åŠ¡ 5: æµ‹è¯• (2-3å°æ—¶)

#### 5.1 æå– PTX
```bash
cd cuda/cuda_runtime/examples

# æå– PTX
clang++ simple_add.cu \
  --cuda-device-only \
  --cuda-gpu-arch=sm_61 \
  -S -o vectorAdd.ptx

# æŸ¥çœ‹ PTX ç¡®è®¤å†…æ ¸å
grep ".entry" vectorAdd.ptx
# åº”è¯¥çœ‹åˆ°ç±»ä¼¼: .entry _Z9vectorAddPKfS0_Pfi(
```

#### 5.2 ç¼–è¯‘æµ‹è¯•ç¨‹åº
```bash
# ç¼–è¯‘ libptxrt
cd ../
mkdir build && cd build
cmake ..
make

# ç¼–è¯‘æµ‹è¯•ç¨‹åºï¼ˆhost-onlyï¼‰
clang++ ../examples/simple_add.cu \
  --cuda-host-only \
  -I.. \
  -L. \
  -lptxrt \
  -o simple_add
```

#### 5.3 è¿è¡Œæµ‹è¯•
```bash
# è®¾ç½® PTX è·¯å¾„
export PTXRT_PTX_PATH=../examples/vectorAdd.ptx

# è¿è¡Œ
./simple_add
```

#### 5.4 é¢„æœŸè¾“å‡º
```
[libptxrt] Fat binary registered
[libptxrt] Kernel registered: _Z9vectorAddPKfS0_Pfi at 0x...
[libptxrt] Launching kernel: _Z9vectorAddPKfS0_Pfi
[libptxrt] Loading PTX: ../examples/vectorAdd.ptx
[libptxrt] Kernel launched successfully
Vector addition successful! Verified 1024 elements.
```

---

## ğŸ› å¸¸è§é—®é¢˜æ’æŸ¥

### é—®é¢˜ 1: é“¾æ¥é”™è¯¯
```
undefined reference to `HostAPI::cuMemAlloc`
```
**è§£å†³**: æ£€æŸ¥ CMakeLists.txt æ˜¯å¦æ­£ç¡®é“¾æ¥äº† PTX VM åº“

### é—®é¢˜ 2: PTX æ–‡ä»¶æ‰¾ä¸åˆ°
```
Failed to load PTX
```
**è§£å†³**: 
- æ£€æŸ¥ PTX æ–‡ä»¶è·¯å¾„
- ä½¿ç”¨ `export PTXRT_PTX_PATH=/full/path/to/file.ptx`

### é—®é¢˜ 3: å†…æ ¸åä¸åŒ¹é…
```
Kernel not found
```
**è§£å†³**: 
- æŸ¥çœ‹ PTX æ–‡ä»¶ä¸­çš„ `.entry` åç§°
- ç¡®ä¿ `__cudaRegisterFunction` è®°å½•çš„åç§°åŒ¹é…

### é—®é¢˜ 4: CUfunction ä¸º 0
**è§£å†³**: éœ€è¦å®ç° `cuModuleGetFunction` ä»å†…æ ¸åè·å–å‡½æ•°å¥æŸ„

---

## ğŸ“Š å®Œæˆæ ‡å‡†

- [x] ç¼–è¯‘é€šè¿‡æ— è­¦å‘Š
- [x] simple_add èƒ½æ‰§è¡Œ
- [x] å†…å­˜åˆ†é…/é‡Šæ”¾å·¥ä½œæ­£å¸¸
- [x] å†…æ ¸èƒ½è¢«è°ƒç”¨
- [x] ç»“æœéªŒè¯é€šè¿‡

---

## â­ï¸ ä¸‹ä¸€æ­¥ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

1. å®ç°çœŸæ­£çš„ Fat Binary è§£æï¼ˆè‡ªåŠ¨æå– PTXï¼‰
2. æ”¯æŒå¤šä¸ªå†…æ ¸å’Œå¤šä¸ª PTX æ–‡ä»¶
3. æ·»åŠ è¯¦ç»†é”™è¯¯ä¿¡æ¯å’Œè°ƒè¯•æ—¥å¿—
4. æ”¯æŒæ›´å¤šå‚æ•°ç±»å‹ï¼ˆç»“æ„ä½“ã€æ•°ç»„ç­‰ï¼‰
5. æ€§èƒ½ä¼˜åŒ–å’Œå†…å­˜æ± 

**æ³¨æ„**: `<<<>>>` è¯­æ³•å·²ç»é€šè¿‡å®ç° `cudaConfigureCall/cudaSetupArgument/cudaLaunch` è‡ªåŠ¨æ”¯æŒï¼ŒClang ä¼šè‡ªåŠ¨è½¬æ¢ã€‚

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

æŸ¥çœ‹ä»¥ä¸‹æ–‡æ¡£ï¼š
- `IMPLEMENTATION_QUICKSTART.md` - è¯¦ç»†å®ç°æŒ‡å—
- `DEVELOPER_GUIDE.md` - API å‚è€ƒ
- `TODO.md` - å®Œæ•´ä»»åŠ¡åˆ—è¡¨

**é¢„è®¡æ€»æ—¶é—´**: 7-9 å°æ—¶ï¼ˆå« <<<>>> è¯­æ³•æ”¯æŒï¼‰
**éš¾åº¦**: â­â­â­ (ä¸­ç­‰)

ğŸš€ å¼€å§‹å®ç°å§ï¼
